{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5w8k65iOekS+LLHzC7zls"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhMy4OCFvVRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b9aff98-e47f-4fff-8f1c-ce146ba91cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.6.1-py3-none-any.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 24.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.8/dist-packages (from selenium) (2022.9.24)\n",
            "Collecting urllib3[socks]~=1.26\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 50.9 MB/s \n",
            "\u001b[?25hCollecting trio~=0.17\n",
            "  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n",
            "\u001b[K     |████████████████████████████████| 384 kB 48.2 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.8/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.8/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Collecting exceptiongroup>=1.0.0rc9\n",
            "  Downloading exceptiongroup-1.0.4-py3-none-any.whl (14 kB)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.8/dist-packages (from trio~=0.17->selenium) (22.1.0)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: sniffio, outcome, h11, exceptiongroup, async-generator, wsproto, urllib3, trio, trio-websocket, selenium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.13 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 exceptiongroup-1.0.4 h11-0.14.0 outcome-1.2.0 selenium-4.6.1 sniffio-1.3.0 trio-0.22.0 trio-websocket-0.9.2 urllib3-1.26.13 wsproto-1.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (4.6.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cssutils\n",
            "  Downloading cssutils-2.6.0-py3-none-any.whl (399 kB)\n",
            "\u001b[K     |████████████████████████████████| 399 kB 30.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: cssutils\n",
            "Successfully installed cssutils-2.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: firebase-admin in /usr/local/lib/python3.8/dist-packages (5.3.0)\n",
            "Requirement already satisfied: cachecontrol>=0.12.6 in /usr/local/lib/python3.8/dist-packages (from firebase-admin) (0.12.11)\n",
            "Requirement already satisfied: google-api-python-client>=1.7.8 in /usr/local/lib/python3.8/dist-packages (from firebase-admin) (1.12.11)\n",
            "Requirement already satisfied: google-cloud-firestore>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from firebase-admin) (2.7.2)\n",
            "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.22.1 in /usr/local/lib/python3.8/dist-packages (from firebase-admin) (2.8.2)\n",
            "Requirement already satisfied: google-cloud-storage>=1.37.1 in /usr/local/lib/python3.8/dist-packages (from firebase-admin) (2.5.0)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.8/dist-packages (from cachecontrol>=0.12.6->firebase-admin) (1.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from cachecontrol>=0.12.6->firebase-admin) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.8/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase-admin) (2.14.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase-admin) (1.57.0)\n",
            "Requirement already satisfied: protobuf<5.0.0dev,>=3.15.0 in /usr/local/lib/python3.8/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase-admin) (3.19.6)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase-admin) (1.50.0)\n",
            "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase-admin) (1.48.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.7.8->firebase-admin) (3.0.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.7.8->firebase-admin) (0.17.4)\n",
            "Requirement already satisfied: six<2dev,>=1.13.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.7.8->firebase-admin) (1.15.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.7.8->firebase-admin) (0.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase-admin) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase-admin) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase-admin) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from google-cloud-firestore>=2.1.0->firebase-admin) (2.3.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-firestore>=2.1.0->firebase-admin) (1.22.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from google-cloud-storage>=1.37.1->firebase-admin) (2.4.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.8/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage>=1.37.1->firebase-admin) (1.5.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase-admin) (0.4.8)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 28.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->cachecontrol>=0.12.6->firebase-admin) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->cachecontrol>=0.12.6->firebase-admin) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->cachecontrol>=0.12.6->firebase-admin) (2022.9.24)\n",
            "Installing collected packages: urllib3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.13\n",
            "    Uninstalling urllib3-1.26.13:\n",
            "      Successfully uninstalled urllib3-1.26.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "selenium 4.6.1 requires urllib3[socks]~=1.26, but you have urllib3 1.25.11 which is incompatible.\u001b[0m\n",
            "Successfully installed urllib3-1.25.11\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:10 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Get:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,563 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,262 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [3,072 kB]\n",
            "Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [1,039 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,334 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,342 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,519 kB]\n",
            "Get:21 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [38.5 kB]\n",
            "Fetched 14.5 MB in 4s (4,129 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 95.1 MB of archives.\n",
            "After this operation, 319 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 107.0.5304.87-0ubuntu11.18.04.1 [1,158 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 107.0.5304.87-0ubuntu11.18.04.1 [83.1 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 107.0.5304.87-0ubuntu11.18.04.1 [5,260 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 107.0.5304.87-0ubuntu11.18.04.1 [5,570 kB]\n",
            "Fetched 95.1 MB in 3s (28.4 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 124015 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_107.0.5304.87-0ubuntu11.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (107.0.5304.87-0ubuntu11.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_107.0.5304.87-0ubuntu11.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (107.0.5304.87-0ubuntu11.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_107.0.5304.87-0ubuntu11.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (107.0.5304.87-0ubuntu11.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_107.0.5304.87-0ubuntu11.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (107.0.5304.87-0ubuntu11.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (107.0.5304.87-0ubuntu11.18.04.1) ...\n",
            "Setting up chromium-browser (107.0.5304.87-0ubuntu11.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (107.0.5304.87-0ubuntu11.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (107.0.5304.87-0ubuntu11.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install selenium\n",
        "!pip install beautifulsoup4\n",
        "!pip install cssutils\n",
        "!pip install firebase-admin\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium import webdriver\n",
        "from bs4 import BeautifulSoup\n",
        "import sys\n",
        "import time\n",
        "import cssutils\n",
        "import re\n",
        "import datetime                            # Imports datetime library\n",
        "import sqlite3 as lite\n",
        "\n",
        "from os import remove\n",
        "\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials\n",
        "from firebase_admin import db\n",
        "\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')"
      ],
      "metadata": {
        "id": "mOXuhdrUvxq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "options.add_argument(\"--incognito\")"
      ],
      "metadata": {
        "id": "x4N4lCxry_SN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#if not firebase_admin._apps:\n",
        " # print(1)\n",
        "  #cred = credentials.Certificate('firebase-sdk.json')\n",
        "  #default_app = firebase_admin.initialize_app(cred, {\n",
        "  #  'databaseURL' : 'https://apptraker-8c803-default-rtdb.firebaseio.com/'\n",
        "  #})\n",
        "\n",
        "\n",
        "\n",
        "cred = credentials.Certificate('firebase-sdk.json')\n",
        "firebase_admin.initialize_app(cred,{\n",
        "  'databaseURL':'https://apptraker-8c803-default-rtdb.firebaseio.com/'\n",
        "})\n"
      ],
      "metadata": {
        "id": "INBCWu-jl2H5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "7a56f5fc-8068-40e7-e356-276c2524d29f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6fa619d598a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCertificate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'firebase-sdk.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m firebase_admin.initialize_app(cred,{\n\u001b[1;32m     12\u001b[0m   \u001b[0;34m'databaseURL'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'https://apptraker-8c803-default-rtdb.firebaseio.com/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/firebase_admin/credentials.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cert)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCertificate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_file_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcert\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                 \u001b[0mjson_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'firebase-sdk.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scrapping Paginas dinamicas Padre"
      ],
      "metadata": {
        "id": "dhZO9MF_z4_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Scraping:\n",
        "  def __init__(self, url, direccion, query, nombreBD):\n",
        "    self.url = url\n",
        "    self.direccion = direccion\n",
        "    self.query = query\n",
        "    self.driver = webdriver.Chrome('chromedriver',options=options)\n",
        "    self.nombreBD = nombreBD\n",
        "    self.soup =\"\"\n",
        "    self.Pagina()\n",
        "    self.RecorrerPagina()\n",
        "    self.Cargar_Pagina()\n",
        "\n",
        "  def Pagina(self):\n",
        "    self.driver.get(self.url+self.direccion+self.query)\n",
        "    self.driver.maximize_window()\n",
        "\n",
        "  def RecorrerPagina(self):\n",
        "    iter=0\n",
        "    while True:\n",
        "      scrollHeight = self.driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
        "      height=250*iter\n",
        "      self.driver.execute_script(\"window.scrollTo(0, \" + str(height) + \");\")\n",
        "      if height > scrollHeight:\n",
        "          print('End of page')\n",
        "          break\n",
        "      time.sleep(0.5)\n",
        "      iter+=1\n",
        "\n",
        "  def Cargar_Pagina(self):\n",
        "    body = self.driver.execute_script(\"return document.body\")\n",
        "    source = body.get_attribute('innerHTML')\n",
        "    self.soup = BeautifulSoup(source, \"html.parser\")"
      ],
      "metadata": {
        "id": "RFLXd_vgzVDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scrapping Hijo Lider"
      ],
      "metadata": {
        "id": "WdkpgHCSzyPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CrearDB:\n",
        "  def __init__(self, db):\n",
        "    self.db = lite.connect(db)\n",
        "\n"
      ],
      "metadata": {
        "id": "pi_7CLOyzip5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InteractuarDB(CrearDB):\n",
        "  def __init__(self, db):\n",
        "    CrearDB.__init__(self, db)\n",
        "    self.cursor = self.db.cursor()\n",
        "  def crearTable(self):\n",
        "    tablas = [\n",
        "              '''\n",
        "          CREATE TABLE IF NOT EXISTS link_notebook(\n",
        "            id integer primary key AUTOINCREMENT,\n",
        "            link TEXT SQLITE_MAX_LENGTH,\n",
        "            sku INTEGER UNIQUE,\n",
        "            prod_img INTEGER\n",
        "          )'''\n",
        "    ]\n",
        "    for tabla in tablas:\n",
        "      self.cursor.execute(tabla)\n",
        "\n",
        "  def incluirLinkDB(self, link, sku,prod_img):\n",
        "    self.cursor.execute(\"\"\"insert into link_notebook(link,sku,prod_img) VALUES (?,?,?)\"\"\", (link, sku,prod_img))\n",
        "    self.db.commit()\n",
        "\n",
        "  def printDB(self):\n",
        "    print(\"entre\")\n",
        "    sentencia = \"SELECT * FROM link_notebook;\"\n",
        "    self.cursor.execute(sentencia)\n",
        "    #imprimir_link = self.cursor.fetchall()\n",
        "    for x in self.cursor.fetchall():\n",
        "      print(x)\n",
        "    #imprimir_link = self.cursor.fetchone()\n",
        "    #print(imprimir_link)\n",
        "    #imprimir_link = self.cursor.fetchone()\n",
        "    #print(imprimir_link)\n",
        "\n",
        "  def estaEnDB(self, busqueda):\n",
        "    db = lite.connect(\"link_lider.db\")\n",
        "    cursor = db.cursor()\n",
        "    cursor.execute(\"SELECT * FROM link_notebook WHERE link=?\", (\"https://www.lider.cl/catalogo/product/sku/1258992/dell-notebook-inspiron-15-3502156intel-celeron4-gb-ram128-gb-ssdwin-10-hsilver\",))\n",
        "    print(cursor.fetchall())\n"
      ],
      "metadata": {
        "id": "jAqPoV3A0WHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Scraping_Lider(Scraping, InteractuarDB):\n",
        "  def __init__(self, url, direccion, query, db):\n",
        "    Scraping.__init__(self, url, direccion, query, db)\n",
        "    InteractuarDB.__init__(self,db)\n",
        "\n",
        "  def Buscar_Link_Scraping(self):\n",
        "    link_completo = \"\"\n",
        "    for producto in self.soup.find_all(\"li\", 'ais-Hits-item'):\n",
        "      link = producto.find(\"a\", style=\"text-decoration: none; height: 100%; display: inline; background-color: white;\")\n",
        "      link_completo = str(self.url + link['href'])\n",
        "      prod = producto.find(\"img\", \"img-hover-zoom img-fluid m-auto \")\n",
        "      #print(link_completo)\n",
        "      #print(prod)\n",
        "      try:\n",
        "\n",
        "        self.incluirLinkDB(link_completo, self.ExtraerSku(link['href']), str(prod['src']))\n",
        "      except:\n",
        "        pass\n",
        "        #self.estaEnDB(link_completo)\n",
        "\n",
        "  def ExtraerSku(self, link):\n",
        "    varSplit = link.split('/')\n",
        "    return str(varSplit[4])\n",
        "\n",
        "  def Extraer_Descripcion(self):\n",
        "    self.Cargar_Pagina()\n",
        "    for descripcion in self.soup.find_all(\"tr\", class_=\"MuiTableRow-root\"):\n",
        "      bandera=0\n",
        "      array=[None, None]\n",
        "      for contenido in descripcion.find_all(\"td\", class_=\"MuiTableCell-root MuiTableCell-body\"):\n",
        "        array[bandera]=contenido.string\n",
        "        bandera+=1\n",
        "      if(array[0]==\"Marca\"):\n",
        "        return (array[1])\n",
        "\n",
        "  def Extraer_Precio(self):\n",
        "    precio = self.soup.find(\"span\", 'pdp-mobile-sales-price')\n",
        "    try:\n",
        "      precio = precio.string\n",
        "      precio = precio.replace(\"$\", \"\")\n",
        "      precio = precio.replace(\" \",\"\")\n",
        "      precio = int(precio.replace(\".\",\"\"))\n",
        "    except:\n",
        "      precio=\" \"\n",
        "    return (precio)\n",
        "\n",
        "  def Extraer_Img(self):\n",
        "\n",
        "    imagen = self.soup.find(\"li\", \"slide selected previous\")\n",
        "    #imagen = imagen.find(\"img\", class_=\"img-fluid\")\n",
        "    #imagen = imagen['src']\n",
        "    return imagen\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W0cm4ua8zxmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Lider:\n",
        "  def __init__(self):\n",
        "    self.link_db = 'link_lider.db'\n",
        "    self.url_lider = \"\"\n",
        "    self.dir_lider_notebook = \"\"\n",
        "    self.query_lider_notebook = \"\"\n",
        "    self.inicio()\n",
        "    self.Scraping_Link()\n",
        "\n",
        "  def inicio(self):\n",
        "    #con = lite.connect(':memory:')\n",
        "    try:\n",
        "      DB = InteractuarDB(self.link_db)\n",
        "      DB.crearTable()\n",
        "    except lite.OperationalError as error:\n",
        "      print(\"Error al abrir:\", error)\n",
        "\n",
        "  def Scraping_Link(self):\n",
        "    self.url_lider = \"https://www.lider.cl\"\n",
        "    self.dir_lider_notebook = \"/catalogo/category/Computación/Computadores/Notebooks\"\n",
        "    self.query_lider_notebook = \"?page=1&sortBy=price_asc&hitsPerPage=200\"\n",
        "    self.Iniciar_Scraping()\n",
        "\n",
        "  def Scraping_Productos(self):\n",
        "    DB = lite.connect(self.link_db)\n",
        "    cursor = DB.cursor()\n",
        "    sentencia = \"SELECT * FROM link_notebook;\"\n",
        "    cursor.execute(sentencia)\n",
        "    ref = db.reference('Productos')\n",
        "    #imprimir_link = self.cursor.fetchall()\n",
        "    for link in cursor.fetchall():\n",
        "      print(link)\n",
        "      pagina_lider = Scraping_Lider(link[1], \"\", \"\", self.link_db)\n",
        "      marca = pagina_lider.Extraer_Descripcion()\n",
        "      precio = pagina_lider.Extraer_Precio()\n",
        "      #imagen = pagina_lider.Extraer_Img()\n",
        "\n",
        "      #print(imagen)\n",
        "      #print(link[1])\n",
        "      ref.push({'id' : str(link[0]),'marca':str(marca),'precio':str(precio),'link':str(link[1]), 'sku':str(link[2]),'imagen':str(link[3])})\n",
        "\n",
        "\n",
        "\n",
        "  def Iniciar_Scraping(self):\n",
        "    pagina_lider = Scraping_Lider(self.url_lider, self.dir_lider_notebook, self.query_lider_notebook, self.link_db)\n",
        "    pagina_lider.Buscar_Link_Scraping()\n",
        "    pagina_lider.printDB()\n",
        "    #pagina_lider.estaEnDB(\"algo\")\n",
        "    #pagina_lider.Extraer_Marca()\n",
        "\n",
        "    self.Scraping_Productos()\n",
        "\n",
        "    #pagina_lider = Scraping_Lider(self.url_lider, self.dir_lider_notebook, self.query_lider_notebook, self.link_db)\n",
        "    #pagina_lider.Extraer_Descripcion()\n",
        "    #pagina_lider.Extraer_Precio()\n",
        "\n"
      ],
      "metadata": {
        "id": "pWc1ifAO4AE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Lider()\n",
        "\n"
      ],
      "metadata": {
        "id": "JP1Sliod1RKQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}